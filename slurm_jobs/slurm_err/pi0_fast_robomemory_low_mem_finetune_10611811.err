16:04:48.638 [I] Running on: iris-hgx-2.stanford.edu                                              (3326196:train.py:251)
16:04:51.773 [I] Created BasePyTreeCheckpointHandler: use_ocdbt=True, use_zarr3=False, pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=<orbax.checkpoint._src.metadata.array_metadata_store.Store object at 0x149d39009c90> (3326196:base_pytree_checkpoint_handler.py:334)
16:04:51.774 [I] Created BasePyTreeCheckpointHandler: use_ocdbt=True, use_zarr3=False, pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=<orbax.checkpoint._src.metadata.array_metadata_store.Store object at 0x149d39009c90> (3326196:base_pytree_checkpoint_handler.py:334)
16:04:51.774 [I] [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID. (3326196:multihost.py:390)
16:04:51.775 [I] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers={'assets': <openpi.training.checkpoints.CallbackHandler object at 0x149c4283de10>, 'train_state': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283da50>, 'params': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283de50>}, handler_registry=None (3326196:checkpoint_manager.py:620)
16:04:51.776 [I] Deferred registration for item: "assets". Adding handler `<openpi.training.checkpoints.CallbackHandler object at 0x149c4283de10>` for item "assets" and save args `<class 'openpi.training.checkpoints.CallbackSave'>` and restore args `<class 'openpi.training.checkpoints.CallbackRestore'>` to `_handler_registry`. (3326196:composite_checkpoint_handler.py:234)
16:04:51.776 [I] Deferred registration for item: "train_state". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283da50>` for item "train_state" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (3326196:composite_checkpoint_handler.py:234)
16:04:51.776 [I] Deferred registration for item: "params". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283de50>` for item "params" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (3326196:composite_checkpoint_handler.py:234)
16:04:51.776 [I] Deferred registration for item: "metrics". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x149c42928310>` for item "metrics" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`. (3326196:composite_checkpoint_handler.py:234)
16:04:51.776 [I] Initialized registry DefaultCheckpointHandlerRegistry({('assets', <class 'openpi.training.checkpoints.CallbackSave'>): <openpi.training.checkpoints.CallbackHandler object at 0x149c4283de10>, ('assets', <class 'openpi.training.checkpoints.CallbackRestore'>): <openpi.training.checkpoints.CallbackHandler object at 0x149c4283de10>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283da50>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283da50>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283de50>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x149c4283de50>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x149c42928310>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x149c42928310>}). (3326196:composite_checkpoint_handler.py:502)
16:04:51.777 [I] orbax-checkpoint version: 0.11.13                                                (3326196:abstract_checkpointer.py:35)
16:04:51.777 [I] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x149c428eff60> timeout: 7200 secs and primary_host=0 for async checkpoint writes (3326196:async_checkpointer.py:170)
16:04:51.787 [I] Read Metadata={'item_handlers': {'assets': 'openpi.training.checkpoints.CallbackHandler', 'params': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'train_state': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler'}, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1752705303684065497, 'commit_timestamp_nsecs': 1752705339214941662, 'custom_metadata': {}} from /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000/_CHECKPOINT_METADATA (3326196:checkpoint.py:226)
16:04:51.788 [W] Missing metrics for step 2000                                                    (3326196:checkpoint_manager.py:1654)
16:04:51.789 [E] File /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000/metrics/metrics not found. (3326196:checkpoint_manager.py:1655)
16:04:51.789 [I] Found 1 checkpoint steps in /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716 (3326196:checkpoint_manager.py:1701)
16:04:51.790 [I] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=1, keep_time_interval=None, keep_period=5000, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=AsyncOptions(timeout_secs=7200, barrier_sync_fn=None, post_finalization_callback=None, create_directories_asynchronously=True), multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None, prevent_write_metrics=False), root_directory=/iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x149c428dce10> (3326196:checkpoint_manager.py:801)
2025/07/16 16:04:52 ERROR failed to get logger path error="error opening log file: open /sailhome/jrpan/.cache/wandb/logs/core-debug-20250716_160452.log: disk quota exceeded"
2025/07/16 16:04:52 INFO server is running addr=127.0.0.1:35881
2025/07/16 16:04:52 INFO Will exit if parent process dies. ppid=3326196
2025/07/16 16:04:52 INFO connection: ManageConnectionData: new connection created id=127.0.0.1:51828
wandb: Currently logged in as: jpan00 (robo-memory) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
2025/07/16 16:04:52 INFO handleInformInit: received streamId=29s9d6jz id=127.0.0.1:51828
2025/07/16 16:04:52 INFO handleInformInit: stream started streamId=29s9d6jz id=127.0.0.1:51828
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /iris/u/jrpan/openpi/wandb/run-20250716_160452-29s9d6jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run lora_10k_0716
wandb: ‚≠êÔ∏è View project at https://wandb.ai/robo-memory/openpi
wandb: üöÄ View run at https://wandb.ai/robo-memory/openpi/runs/29s9d6jz
Some kwargs in processor config are unused and will not have any effect: action_dim, vocab_size, scale, min_token, time_horizon. 
Some kwargs in processor config are unused and will not have any effect: action_dim, vocab_size, scale, min_token, time_horizon. 
16:04:57.556 [I] Loaded norm stats from /iris/u/jrpan/openpi/assets/pi0_fast_robomemory_low_mem_finetune/jennypan00/pi0_fast_ft_droid_lerobot (3326196:config.py:170)
Some kwargs in processor config are unused and will not have any effect: action_dim, vocab_size, scale, min_token, time_horizon. 
Some kwargs in processor config are unused and will not have any effect: action_dim, vocab_size, scale, min_token, time_horizon. 
16:05:01.843 [I] Loaded norm stats from /iris/u/jrpan/openpi/assets/pi0_fast_robomemory_low_mem_finetune/jennypan00/pi0_fast_ft_droid_lerobot (3326196:config.py:170)
16:05:48.204 [I] Initialized data loader:
[0].images['base_0_rgb']: (128, 224, 224, 3)@float32
[0].images['base_1_rgb']: (128, 224, 224, 3)@float32
[0].images['wrist_0_rgb']: (128, 224, 224, 3)@float32
[0].image_masks['base_0_rgb']: (128,)@bool
[0].image_masks['base_1_rgb']: (128,)@bool
[0].image_masks['wrist_0_rgb']: (128,)@bool
[0].state: (128, 8)@float32
[0].tokenized_prompt: (128, 180)@int32
[0].tokenized_prompt_mask: (128, 180)@bool
[0].token_ar_mask: (128, 180)@int32
[0].token_loss_mask: (128, 180)@bool
[1]: (128, 10, 8)@float32 (3326196:train.py:292)
16:05:51.404 [I] Initialized train state:
['PaliGemma']['img']['Transformer']['encoder_norm']['bias'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoder_norm']['scale'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['bias'].value: (27, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value: (27, 1152, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value: (27, 4304, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value: (27, 16, 72, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['embedding']['bias'].value: (1152,)@float32
['PaliGemma']['img']['embedding']['kernel'].value: (14, 14, 3, 1152)@float32
['PaliGemma']['img']['head']['bias'].value: (2048,)@float32
['PaliGemma']['img']['head']['kernel'].value: (1152, 2048)@float32
['PaliGemma']['img']['pos_embedding'].value: (1, 256, 1152)@float32
['PaliGemma']['llm']['embedder']['input_embedding'].value: (257152, 2048)@bfloat16
['PaliGemma']['llm']['final_norm']['scale'].value: (2048,)@bfloat16
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['lora_a'].value: (18, 8, 256, 16)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['lora_b'].value: (18, 8, 16, 2048)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value: (18, 8, 256, 2048)@bfloat16
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['lora_a'].value: (18, 2, 1, 2048, 16)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['lora_b'].value: (18, 2, 1, 16, 256)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value: (18, 2, 1, 2048, 256)@bfloat16
['PaliGemma']['llm']['layers']['attn']['q_einsum']['lora_a'].value: (18, 8, 2048, 16)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum']['lora_b'].value: (18, 8, 16, 256)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value: (18, 8, 2048, 256)@bfloat16
['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value: (18, 2, 2048, 16384)@bfloat16
['PaliGemma']['llm']['layers']['mlp']['gating_einsum_lora_a'].value: (18, 2, 2048, 16)@float32
['PaliGemma']['llm']['layers']['mlp']['gating_einsum_lora_b'].value: (18, 2, 16, 16384)@float32
['PaliGemma']['llm']['layers']['mlp']['linear'].value: (18, 16384, 2048)@bfloat16
['PaliGemma']['llm']['layers']['mlp']['linear_lora_a'].value: (18, 16384, 16)@float32
['PaliGemma']['llm']['layers']['mlp']['linear_lora_b'].value: (18, 16, 2048)@float32
['PaliGemma']['llm']['layers']['pre_attention_norm']['scale'].value: (18, 2048)@bfloat16
['PaliGemma']['llm']['layers']['pre_ffw_norm']['scale'].value: (18, 2048)@bfloat16 (3326196:train.py:303)
16:05:51.412 [I] Restoring checkpoint from /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000. (3326196:checkpointer.py:298)
/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/type_handlers.py:1251: UserWarning: Sharding info not provided when restoring. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.
  warnings.warn(
16:05:51.443 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.446 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.449 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.452 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.456 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.459 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.462 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.466 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.469 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.473 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.477 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.480 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.485 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.488 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.491 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.495 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.498 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.502 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.506 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.510 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.512 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.516 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.520 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.523 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.526 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.529 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.532 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.535 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.537 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.539 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.541 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.543 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.545 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.547 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.549 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.551 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.553 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.557 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.559 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.561 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.564 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
16:05:51.567 [E] The available devices are different from the devices used to save the checkpoint.  Please restore checkpoint by passing new shardings for target devices. Original=[[DeviceMetadata(id=0)], [DeviceMetadata(id=1)], [DeviceMetadata(id=2)], [DeviceMetadata(id=3)]], current available=[CudaDevice(id=0), CudaDevice(id=1)] (3326196:sharding.py:358)
Traceback (most recent call last):
  File "/iris/u/jrpan/openpi/scripts/train.py", line 375, in <module>
    main(_config.cli())
  File "/iris/u/jrpan/openpi/scripts/train.py", line 306, in main
    train_state = _checkpoints.restore_state(checkpoint_manager, train_state, data_loader)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/src/openpi/training/checkpoints.py", line 100, in restore_state
    restored = checkpoint_manager.restore(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1608, in restore
    restored = self._checkpointer.restore(restore_directory, args=args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/checkpointers/async_checkpointer.py", line 558, in restore
    return super().restore(directory, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/checkpointers/checkpointer.py", line 300, in restore
    restored = self._restore(directory, args=ckpt_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/checkpointers/checkpointer.py", line 319, in _restore
    return self._handler.restore(directory, args=args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/composite_checkpoint_handler.py", line 837, in restore
    restored[item_name] = handler.restore(
                          ^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/pytree_checkpoint_handler.py", line 796, in restore
    return self._handler_impl.restore(directory, args=args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/base_pytree_checkpoint_handler.py", line 760, in restore
    tree_memory_size, restored_item = asyncio_utils.run_sync(
                                      ^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/asyncio_utils.py", line 50, in run_sync
    return asyncio.run(coro)
           ^^^^^^^^^^^^^^^^^
  File "/sailhome/jrpan/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/sailhome/jrpan/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sailhome/jrpan/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/base_pytree_checkpoint_handler.py", line 584, in _maybe_deserialize
    deserialized_batches += await asyncio.gather(*deserialized_batches_ops)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/type_handlers.py", line 1314, in deserialize
    *ret, array_metadatas = await asyncio.gather(*deserialize_ops)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/serialization.py", line 527, in async_deserialize
    raise ValueError(
ValueError: sharding passed to deserialization should be specified, concrete and an instance of `jax.sharding.Sharding`. Got None
2025/07/16 16:05:52 INFO handleInformTeardown: server teardown initiated id=127.0.0.1:51828
2025/07/16 16:05:52 INFO connection: closing id=127.0.0.1:51828
2025/07/16 16:05:52 INFO server is shutting down
2025/07/16 16:05:52 INFO connection: closed successfully id=127.0.0.1:51828
2025/07/16 16:05:53 INFO handleInformTeardown: server shutdown complete id=127.0.0.1:51828
2025/07/16 16:05:53 INFO connection: ManageConnectionData: connection closed id=127.0.0.1:51828
2025/07/16 16:05:53 INFO server is closed
