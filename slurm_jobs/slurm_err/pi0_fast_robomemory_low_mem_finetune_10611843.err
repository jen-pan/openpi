16:15:59.216 [I] Running on: iris-hgx-2.stanford.edu                                              (3333303:train.py:251)
16:16:01.531 [I] Created BasePyTreeCheckpointHandler: use_ocdbt=True, use_zarr3=False, pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=<orbax.checkpoint._src.metadata.array_metadata_store.Store object at 0x14cfa8d69c90> (3333303:base_pytree_checkpoint_handler.py:334)
16:16:01.531 [I] Created BasePyTreeCheckpointHandler: use_ocdbt=True, use_zarr3=False, pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=<orbax.checkpoint._src.metadata.array_metadata_store.Store object at 0x14cfa8d69c90> (3333303:base_pytree_checkpoint_handler.py:334)
16:16:01.532 [I] [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID. (3333303:multihost.py:390)
16:16:01.533 [I] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers={'assets': <openpi.training.checkpoints.CallbackHandler object at 0x14ce87bdffd0>, 'train_state': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14ce87c463d0>, 'params': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14d349a77a90>}, handler_registry=None (3333303:checkpoint_manager.py:620)
16:16:01.534 [I] Deferred registration for item: "assets". Adding handler `<openpi.training.checkpoints.CallbackHandler object at 0x14ce87bdffd0>` for item "assets" and save args `<class 'openpi.training.checkpoints.CallbackSave'>` and restore args `<class 'openpi.training.checkpoints.CallbackRestore'>` to `_handler_registry`. (3333303:composite_checkpoint_handler.py:234)
16:16:01.534 [I] Deferred registration for item: "train_state". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14ce87c463d0>` for item "train_state" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (3333303:composite_checkpoint_handler.py:234)
16:16:01.534 [I] Deferred registration for item: "params". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14d349a77a90>` for item "params" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (3333303:composite_checkpoint_handler.py:234)
16:16:01.534 [I] Deferred registration for item: "metrics". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x14ce87c45c50>` for item "metrics" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`. (3333303:composite_checkpoint_handler.py:234)
16:16:01.534 [I] Initialized registry DefaultCheckpointHandlerRegistry({('assets', <class 'openpi.training.checkpoints.CallbackSave'>): <openpi.training.checkpoints.CallbackHandler object at 0x14ce87bdffd0>, ('assets', <class 'openpi.training.checkpoints.CallbackRestore'>): <openpi.training.checkpoints.CallbackHandler object at 0x14ce87bdffd0>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14ce87c463d0>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14ce87c463d0>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14d349a77a90>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14d349a77a90>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x14ce87c45c50>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x14ce87c45c50>}). (3333303:composite_checkpoint_handler.py:502)
16:16:01.535 [I] orbax-checkpoint version: 0.11.13                                                (3333303:abstract_checkpointer.py:35)
16:16:01.535 [I] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x14ce87d0bf60> timeout: 7200 secs and primary_host=0 for async checkpoint writes (3333303:async_checkpointer.py:170)
16:16:01.542 [I] Read Metadata={'item_handlers': {'assets': 'openpi.training.checkpoints.CallbackHandler', 'params': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler', 'train_state': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler'}, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1752705303684065497, 'commit_timestamp_nsecs': 1752705339214941662, 'custom_metadata': {}} from /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000/_CHECKPOINT_METADATA (3333303:checkpoint.py:226)
16:16:01.543 [W] Missing metrics for step 2000                                                    (3333303:checkpoint_manager.py:1654)
16:16:01.544 [E] File /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000/metrics/metrics not found. (3333303:checkpoint_manager.py:1655)
16:16:01.544 [I] Found 1 checkpoint steps in /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716 (3333303:checkpoint_manager.py:1701)
16:16:01.545 [I] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=1, keep_time_interval=None, keep_period=5000, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=AsyncOptions(timeout_secs=7200, barrier_sync_fn=None, post_finalization_callback=None, create_directories_asynchronously=True), multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None, prevent_write_metrics=False), root_directory=/iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x14ce87c46e10> (3333303:checkpoint_manager.py:801)
2025/07/16 16:16:01 ERROR failed to get logger path error="error opening log file: open /sailhome/jrpan/.cache/wandb/logs/core-debug-20250716_161601.log: disk quota exceeded"
2025/07/16 16:16:01 INFO Will exit if parent process dies. ppid=3333303
2025/07/16 16:16:01 INFO server is running addr=127.0.0.1:41129
2025/07/16 16:16:01 INFO connection: ManageConnectionData: new connection created id=127.0.0.1:35504
wandb: Currently logged in as: jpan00 (robo-memory) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
2025/07/16 16:16:02 INFO handleInformInit: received streamId=29s9d6jz id=127.0.0.1:35504
2025/07/16 16:16:02 INFO handleInformInit: stream started streamId=29s9d6jz id=127.0.0.1:35504
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /iris/u/jrpan/openpi/wandb/run-20250716_161601-29s9d6jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run lora_10k_0716
wandb: ‚≠êÔ∏è View project at https://wandb.ai/robo-memory/openpi
wandb: üöÄ View run at https://wandb.ai/robo-memory/openpi/runs/29s9d6jz
Some kwargs in processor config are unused and will not have any effect: scale, vocab_size, time_horizon, min_token, action_dim. 
Some kwargs in processor config are unused and will not have any effect: scale, vocab_size, time_horizon, min_token, action_dim. 
16:16:05.943 [I] Loaded norm stats from /iris/u/jrpan/openpi/assets/pi0_fast_robomemory_low_mem_finetune/jennypan00/pi0_fast_ft_droid_lerobot (3333303:config.py:170)
Some kwargs in processor config are unused and will not have any effect: scale, vocab_size, time_horizon, min_token, action_dim. 
Some kwargs in processor config are unused and will not have any effect: scale, vocab_size, time_horizon, min_token, action_dim. 
16:16:09.416 [I] Loaded norm stats from /iris/u/jrpan/openpi/assets/pi0_fast_robomemory_low_mem_finetune/jennypan00/pi0_fast_ft_droid_lerobot (3333303:config.py:170)
16:16:44.164 [I] Initialized data loader:
[0].images['base_0_rgb']: (128, 224, 224, 3)@float32
[0].images['base_1_rgb']: (128, 224, 224, 3)@float32
[0].images['wrist_0_rgb']: (128, 224, 224, 3)@float32
[0].image_masks['base_0_rgb']: (128,)@bool
[0].image_masks['base_1_rgb']: (128,)@bool
[0].image_masks['wrist_0_rgb']: (128,)@bool
[0].state: (128, 8)@float32
[0].tokenized_prompt: (128, 180)@int32
[0].tokenized_prompt_mask: (128, 180)@bool
[0].token_ar_mask: (128, 180)@int32
[0].token_loss_mask: (128, 180)@bool
[1]: (128, 10, 8)@float32 (3333303:train.py:292)
16:16:47.037 [I] Initialized train state:
['PaliGemma']['img']['Transformer']['encoder_norm']['bias'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoder_norm']['scale'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['bias'].value: (27, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value: (27, 1152, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value: (27, 4304, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value: (27, 16, 72, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['embedding']['bias'].value: (1152,)@float32
['PaliGemma']['img']['embedding']['kernel'].value: (14, 14, 3, 1152)@float32
['PaliGemma']['img']['head']['bias'].value: (2048,)@float32
['PaliGemma']['img']['head']['kernel'].value: (1152, 2048)@float32
['PaliGemma']['img']['pos_embedding'].value: (1, 256, 1152)@float32
['PaliGemma']['llm']['embedder']['input_embedding'].value: (257152, 2048)@bfloat16
['PaliGemma']['llm']['final_norm']['scale'].value: (2048,)@bfloat16
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['lora_a'].value: (18, 8, 256, 16)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['lora_b'].value: (18, 8, 16, 2048)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value: (18, 8, 256, 2048)@bfloat16
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['lora_a'].value: (18, 2, 1, 2048, 16)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['lora_b'].value: (18, 2, 1, 16, 256)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value: (18, 2, 1, 2048, 256)@bfloat16
['PaliGemma']['llm']['layers']['attn']['q_einsum']['lora_a'].value: (18, 8, 2048, 16)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum']['lora_b'].value: (18, 8, 16, 256)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value: (18, 8, 2048, 256)@bfloat16
['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value: (18, 2, 2048, 16384)@bfloat16
['PaliGemma']['llm']['layers']['mlp']['gating_einsum_lora_a'].value: (18, 2, 2048, 16)@float32
['PaliGemma']['llm']['layers']['mlp']['gating_einsum_lora_b'].value: (18, 2, 16, 16384)@float32
['PaliGemma']['llm']['layers']['mlp']['linear'].value: (18, 16384, 2048)@bfloat16
['PaliGemma']['llm']['layers']['mlp']['linear_lora_a'].value: (18, 16384, 16)@float32
['PaliGemma']['llm']['layers']['mlp']['linear_lora_b'].value: (18, 16, 2048)@float32
['PaliGemma']['llm']['layers']['pre_attention_norm']['scale'].value: (18, 2048)@bfloat16
['PaliGemma']['llm']['layers']['pre_ffw_norm']['scale'].value: (18, 2048)@bfloat16 (3333303:train.py:303)
16:16:47.044 [I] Restoring checkpoint from /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000. (3333303:checkpointer.py:298)
/iris/u/jrpan/openpi/.venv/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/type_handlers.py:1251: UserWarning: Sharding info not provided when restoring. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.
  warnings.warn(
wandb: WARNING Tried to log to step 0 that is less than the current step 2901. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
16:17:10.137 [I] [process=0] /jax/checkpoint/read/bytes_per_sec: 1.1 GiB/s (total bytes: 25.3 GiB) (time elapsed: 23 seconds) (per-host) (3333303:base_pytree_checkpoint_handler.py:114)
16:17:23.796 [I] [process=0] /jax/checkpoint/read/bytes_per_sec: 992.4 MiB/s (total bytes: 13.2 GiB) (time elapsed: 13 seconds) (per-host) (3333303:base_pytree_checkpoint_handler.py:114)
16:17:23.797 [I] Finished restoring checkpoint in 36.75 seconds from /iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716/2000. (3333303:checkpointer.py:309)
16:17:23.797 [I] {'step': 2000, 'event_type': 'restore', 'directory': '/iris/u/jrpan/openpi/checkpoints/pi0_fast_robomemory_low_mem_finetune/lora_10k_0716', 'checkpointer_start_time': 1752707807.0445857, 'checkpointer_duration_secs': 36.75313472747803, 'checkpoint_manager_start_time': 1752707807.0440955, 'checkpoint_manager_duration_secs': 36.75362777709961} (3333303:standard_logger.py:34)
16:17:23.819 [I] Progress on: 2.00kit/10.0kit rate:- remaining:? elapsed:00:00 postfix:-          (3333303:tqdm_logging.py:145)
16:17:34.406 [I] Progress on: 2.00kit/10.0kit rate:2.0s/it remaining:4:28:34 elapsed:00:10 postfix:- (3333303:tqdm_logging.py:145)
16:17:45.602 [I] Progress on: 2.01kit/10.0kit rate:1.3s/it remaining:2:49:46 elapsed:00:21 postfix:- (3333303:tqdm_logging.py:145)
16:17:56.596 [I] Progress on: 2.02kit/10.0kit rate:1.2s/it remaining:2:42:15 elapsed:00:32 postfix:- (3333303:tqdm_logging.py:145)
16:18:07.731 [I] Progress on: 2.03kit/10.0kit rate:1.2s/it remaining:2:44:31 elapsed:00:43 postfix:- (3333303:tqdm_logging.py:145)
16:18:18.835 [I] Progress on: 2.04kit/10.0kit rate:1.2s/it remaining:2:42:54 elapsed:00:55 postfix:- (3333303:tqdm_logging.py:145)
16:18:30.050 [I] Progress on: 2.05kit/10.0kit rate:1.2s/it remaining:2:45:33 elapsed:01:06 postfix:- (3333303:tqdm_logging.py:145)
16:18:41.112 [I] Progress on: 2.06kit/10.0kit rate:1.2s/it remaining:2:42:14 elapsed:01:17 postfix:- (3333303:tqdm_logging.py:145)
16:18:52.265 [I] Progress on: 2.07kit/10.0kit rate:1.2s/it remaining:2:44:55 elapsed:01:28 postfix:- (3333303:tqdm_logging.py:145)
16:19:02.291 [I] Progress on: 2.08kit/10.0kit rate:1.3s/it remaining:2:45:24 elapsed:01:38 postfix:- (3333303:tqdm_logging.py:145)
16:19:13.393 [I] Progress on: 2.08kit/10.0kit rate:1.2s/it remaining:2:43:16 elapsed:01:49 postfix:- (3333303:tqdm_logging.py:145)
16:19:24.569 [I] Progress on: 2.09kit/10.0kit rate:1.3s/it remaining:2:45:07 elapsed:02:00 postfix:- (3333303:tqdm_logging.py:145)
16:19:34.864 [I] Progress on: 2.10kit/10.0kit rate:1.3s/it remaining:2:50:53 elapsed:02:11 postfix:- (3333303:tqdm_logging.py:145)
wandb: WARNING Tried to log to step 2100 that is less than the current step 2901. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
16:19:45.930 [I] Progress on: 2.11kit/10.0kit rate:1.2s/it remaining:2:41:57 elapsed:02:22 postfix:- (3333303:tqdm_logging.py:145)
16:19:57.093 [I] Progress on: 2.12kit/10.0kit rate:1.3s/it remaining:2:44:25 elapsed:02:33 postfix:- (3333303:tqdm_logging.py:145)
16:20:08.323 [I] Progress on: 2.13kit/10.0kit rate:1.3s/it remaining:2:44:24 elapsed:02:44 postfix:- (3333303:tqdm_logging.py:145)
16:20:19.548 [I] Progress on: 2.14kit/10.0kit rate:1.3s/it remaining:2:44:02 elapsed:02:55 postfix:- (3333303:tqdm_logging.py:145)
16:20:29.689 [I] Progress on: 2.15kit/10.0kit rate:1.3s/it remaining:2:48:25 elapsed:03:05 postfix:- (3333303:tqdm_logging.py:145)
16:20:40.870 [I] Progress on: 2.15kit/10.0kit rate:1.2s/it remaining:2:43:00 elapsed:03:17 postfix:- (3333303:tqdm_logging.py:145)
16:20:51.015 [I] Progress on: 2.16kit/10.0kit rate:1.7s/it remaining:3:40:26 elapsed:03:27 postfix:- (3333303:tqdm_logging.py:145)
16:21:01.243 [I] Progress on: 2.17kit/10.0kit rate:1.3s/it remaining:2:50:42 elapsed:03:37 postfix:- (3333303:tqdm_logging.py:145)
16:21:12.340 [I] Progress on: 2.18kit/10.0kit rate:1.2s/it remaining:2:40:37 elapsed:03:48 postfix:- (3333303:tqdm_logging.py:145)
16:21:23.488 [I] Progress on: 2.19kit/10.0kit rate:1.2s/it remaining:2:41:24 elapsed:03:59 postfix:- (3333303:tqdm_logging.py:145)
16:21:33.509 [I] Progress on: 2.20kit/10.0kit rate:1.2s/it remaining:2:42:31 elapsed:04:09 postfix:- (3333303:tqdm_logging.py:145)
wandb: WARNING Tried to log to step 2200 that is less than the current step 2901. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
16:21:43.679 [I] Progress on: 2.20kit/10.0kit rate:1.3s/it remaining:2:43:15 elapsed:04:19 postfix:- (3333303:tqdm_logging.py:145)
16:21:54.834 [I] Progress on: 2.21kit/10.0kit rate:1.3s/it remaining:2:43:13 elapsed:04:31 postfix:- (3333303:tqdm_logging.py:145)
16:22:05.873 [I] Progress on: 2.22kit/10.0kit rate:1.2s/it remaining:2:39:05 elapsed:04:42 postfix:- (3333303:tqdm_logging.py:145)
16:22:16.920 [I] Progress on: 2.23kit/10.0kit rate:1.2s/it remaining:2:38:39 elapsed:04:53 postfix:- (3333303:tqdm_logging.py:145)
16:22:28.318 [I] Progress on: 2.24kit/10.0kit rate:1.3s/it remaining:2:52:00 elapsed:05:04 postfix:- (3333303:tqdm_logging.py:145)
16:22:38.326 [I] Progress on: 2.25kit/10.0kit rate:1.3s/it remaining:2:42:19 elapsed:05:14 postfix:- (3333303:tqdm_logging.py:145)
slurmstepd: error: *** JOB 10611843 ON iris-hgx-2 CANCELLED AT 2025-07-16T16:22:48 ***
